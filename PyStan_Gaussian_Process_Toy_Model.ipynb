{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as pl\n",
    "import pystan\n",
    "from pystan import StanModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Generate data from a Gaussian Process Simulator using PyStan:\n",
    "\n",
    "# Simulator model:\n",
    "\n",
    "# first model is a univariate model:\n",
    "\n",
    "GP_simulator_model_1 = \"\"\"\n",
    "\n",
    "data {\n",
    "  int<lower=1> N;\n",
    "  real x[N];\n",
    "}\n",
    "\n",
    "transformed data {\n",
    "  vector[N] mu;\n",
    "  cov_matrix[N] Sigma;\n",
    "  for (i in 1:N)\n",
    "    mu[i] <- 0;\n",
    "  for (i in 1:N)\n",
    "    for (j in 1:N) {\n",
    "      Sigma[i, j] <- exp(-pow(x[i] - x[j], 2)) + if_else(i==j, 0.1, 0.0);\n",
    "      // The covariance matrix Sigma is not being computed efficiently here; \n",
    "      // see Section Section 15.3 of Stan Manual for a better approach.\n",
    "    }      \n",
    "}\n",
    "\n",
    "parameters {\n",
    "  vector[N] y;\n",
    "}\n",
    "\n",
    "model {\n",
    "  y ~ multi_normal(mu, Sigma);\n",
    "}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Compiled Stan Model\n",
    "sm_sim_univariate = StanModel(model_code=GP_simulator_model_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Second model is a multivariate model:\n",
    "\n",
    "GP_simulator_model_2 = \"\"\"\n",
    "\n",
    "data {\n",
    "  int<lower=1> D;\n",
    "  int<lower=1> N;\n",
    "  vector[D] x[N];\n",
    "}\n",
    "\n",
    "transformed data {\n",
    "  vector[N] mu;\n",
    "  cov_matrix[N] Sigma;\n",
    "  for (i in 1:N)\n",
    "    mu[i] <- 0;\n",
    "  for (i in 1:N)\n",
    "    for (j in 1:N) {\n",
    "      Sigma[i, j] <- exp(-dot_self(x[i] - x[j])) + if_else(i==j, 0.1, 0.0);\n",
    "      // The squared Euclidean distance calculation is done using the \n",
    "      // dot_self function, which returns the dot product of its argument \n",
    "      // with itself, here x[i] - x[j].\n",
    "    }      \n",
    "}\n",
    "\n",
    "parameters {\n",
    "  vector[N] y;\n",
    "}\n",
    "\n",
    "model {\n",
    "  y ~ multi_normal(mu, Sigma);\n",
    "}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Compiled Stan Model\n",
    "sm_sim_multivariate = StanModel(model_code=GP_simulator_model_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# first model is a univariate model:\n",
    "\n",
    "GP_simulator_model_3 = \"\"\"\n",
    "\n",
    "data {\n",
    "  int<lower=1> N;\n",
    "  real x[N];\n",
    "}\n",
    "\n",
    "transformed data {\n",
    "  vector[N] mu;\n",
    "  cov_matrix[N] Sigma;\n",
    "  matrix[N, N] L;\n",
    "  for (i in 1:N)\n",
    "    mu[i] <- 0;\n",
    "  for (i in 1:N)\n",
    "    for (j in 1:N) {\n",
    "      Sigma[i, j] <- exp(-pow(x[i] - x[j], 2)) + if_else(i==j, 0.1, 0.0);\n",
    "      // The covariance matrix Sigma is not being computed efficiently here; \n",
    "      // see Section Section 15.3 of Stan Manual for a better approach.\n",
    "    }  \n",
    "    L <- cholesky_decompose(Sigma);\n",
    "}\n",
    "\n",
    "parameters {\n",
    "  vector[N] z;\n",
    "}\n",
    "\n",
    "model {\n",
    "  z ~ normal(0, 1);\n",
    "}\n",
    "\n",
    "generated quantities {\n",
    "  vector[N] y;\n",
    "  y <- mu + L * z;\n",
    "}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Compiled Stan Model\n",
    "sm_sim_univariate_with_Cholesky = StanModel(model_code=GP_simulator_model_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Tutorial for DFM Goerge code. \n",
    "# Generate some fake noisy data.\n",
    "N = 10\n",
    "x = N * np.sort(np.random.rand(N))\n",
    "yerr = 0.2 * np.ones_like(x)\n",
    "y = np.sin(x) + yerr * np.random.randn(len(x))\n",
    "\n",
    "print(x)\n",
    "print(yerr)\n",
    "print(y)\n",
    "\n",
    "pl.errorbar(x, y, yerr=yerr, fmt=\".k\", capsize=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "GP_test_model = \"\"\"\n",
    "\n",
    "data {\n",
    "  int<lower=1> N;\n",
    "  vector[N] x;\n",
    "  vector[N] y;\n",
    "  }\n",
    "\n",
    "transformed data {\n",
    "  vector[N] mu;\n",
    "  for (i in 1:N) \n",
    "    mu[i] <- 0;\n",
    "  }\n",
    "\n",
    "parameters {\n",
    "  real<lower=0> eta_sq;\n",
    "  real<lower=0> inv_rho_sq;\n",
    "  real<lower=0> sigma_sq;\n",
    "}\n",
    "\n",
    "transformed parameters {\n",
    "  real<lower=0> rho_sq;\n",
    "  rho_sq <- inv(inv_rho_sq);\n",
    "} \n",
    "\n",
    "model {\n",
    "  matrix[N, N] Sigma;\n",
    "  // off-diagonal elements\n",
    "  for (i in 1:(N-1)) {\n",
    "    for (j in (i+1):N) {\n",
    "      Sigma[i, j] <- eta_sq * exp(-rho_sq * pow(x[i] - x[j],2));\n",
    "      Sigma[j, i] <- Sigma[i, j];\n",
    "    } \n",
    "  }\n",
    "      // diagonal elements\n",
    "  for (k in 1:N)\n",
    "    Sigma[k, k] <- eta_sq + sigma_sq;  // + jitter\n",
    "\n",
    "// hyperpriors: \n",
    "// Because the hyperparameters are required to be positive and expected to \n",
    "// have reasonably small values, broad half-Cauchy distribu- tions act as \n",
    "// quite vague priors which could just as well be uniform over a constrained \n",
    "// range of values.\n",
    "\n",
    "//  eta_sq ~ cauchy(0, );\n",
    "//  inv_rho_sq ~ cauchy(0, 5);\n",
    "//  sigma_sq ~ cauchy(0, 5);\n",
    "\n",
    "  eta_sq ~ gamma(1,1); // increasing alpha and beta makes variance smaller, but depends.\n",
    "  inv_rho_sq ~ uniform(0, 2);\n",
    "  sigma_sq ~ gamma(1, 1);\n",
    "\n",
    "\n",
    "  y ~ multi_normal(mu, Sigma);\n",
    "}\n",
    "  \n",
    "\"\"\"\n",
    "\n",
    "# Compiled Stan Model\n",
    "sm = StanModel(model_code=GP_test_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = {'N':N, 'x':x, 'y':y}\n",
    "\n",
    "# Could set initial value to Max Likelihood solution without radius errors\n",
    "#init = [{'lnf0':0.66,'alpha':-1.82,'beta':-0.65}]\n",
    "\n",
    "fit = sm.sampling(data=data, iter=1000, chains=5, n_jobs=-1)\n",
    "\n",
    "#get_inits(fit)\n",
    "\n",
    "# Return a dictionary of arrays of posterior samples\n",
    "la = fit.extract(permuted=True)  \n",
    "#mu = la['mu']\n",
    "#Sigma = la['Sigma']\n",
    "\n",
    "eta_sq = la['eta_sq']\n",
    "inv_rho_sq = la['inv_rho_sq']\n",
    "sigma_sq = la['sigma_sq']\n",
    "rho_sq = la['rho_sq']\n",
    "\n",
    "a = fit.extract(permuted=False)\n",
    "print(fit)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import corner\n",
    "\n",
    "corner.corner(np.hstack((eta_sq.reshape(-1,1), inv_rho_sq.reshape(-1,1), sigma_sq.reshape(-1,1), rho_sq.reshape(-1,1))), labels=[r\"eta_sq\", r\"inv_rho_sq\", r\"sigma_sq\", r\"rho_sq\"]);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print(sm)\n",
    "print(eta_sq.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### calculate the mean for the random variable y \n",
    "#tilda for each vector of hyper parameters using the formula \n",
    "# for this.  Then plot the mean and std for each t value (value you want to predict). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print(la)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print(a)\n",
    "#print(a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fit.traceplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##  Build a prediction function\n",
    "import pylab as py\n",
    "import pandas as pd\n",
    "\n",
    "##### PREDICTION ####\n",
    " \n",
    "# make a dataframe of parameter estimates for all chains\n",
    "# params = pd.DataFrame({'eta_sq': fit.extract('eta_sq', permuted=True), 'sigma_sq': fit.extract('sigma_sq', permuted=True), , 'rho_sq': fit.extract('rho_sq', permuted=True)})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Predictive Inference with a Gaussian Process:\n",
    "\n",
    "GP_test_predict_model_1 = \"\"\"\n",
    "\n",
    "data {\n",
    "  int<lower=1> N1;\n",
    "  int<lower=1> N2;\n",
    "  vector[N1] x1;\n",
    "  vector[N1] y1;\n",
    "  vector[N2] x2;\n",
    "}\n",
    "\n",
    "transformed data {\n",
    "  int<lower=1> N;\n",
    "  vector[N1+N2] x;\n",
    "  vector[N1+N2] mu;\n",
    "  cov_matrix[N1+N2] Sigma;\n",
    "  N <- N1 + N2;\n",
    "  for (n in 1:N1) \n",
    "    x[n] <- x1[n]; \n",
    "  for (n in 1:N2) \n",
    "    x[N1 + n] <- x2[n];\n",
    "  for (i in 1:N) \n",
    "    mu[i] <- 0;\n",
    "  for (i in 1:N)\n",
    "    for (j in 1:N) {\n",
    "      Sigma[i, j] <- exp(-pow(x[i] - x[j],2)) + if_else(i==j, 0.1, 0.0);\n",
    "    }\n",
    "}\n",
    "    \n",
    "parameters {\n",
    "  vector[N2] y2;\n",
    "}\n",
    "\n",
    "model {\n",
    "  vector[N] y;\n",
    "  for (n in 1:N1) y[n] <- y1[n];\n",
    "  for (n in 1:N2) y[N1 + n] <- y2[n];\n",
    "  y ~ multi_normal(mu, Sigma);\n",
    "}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Compiled Stan Model\n",
    "sm_p = StanModel(model_code=GP_test_predict_model_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Cholesky Factorization Speedup of above model:\n",
    "\n",
    "GP_test_predict_model_2 = \"\"\"\n",
    "\n",
    "data {\n",
    "  int<lower=1> N1;\n",
    "  int<lower=1> N2;\n",
    "  vector[N1] x1;\n",
    "  vector[N1] y1;\n",
    "  vector[N2] x2;\n",
    "}\n",
    "\n",
    "transformed data {\n",
    "  int<lower=1> N;\n",
    "  vector[N1+N2] x;\n",
    "  vector[N1+N2] mu;\n",
    "  cov_matrix[N1+N2] Sigma;\n",
    "  matrix[N1+N2, N1+N2] L;\n",
    "  N <- N1 + N2;\n",
    "  for (n in 1:N1) \n",
    "    x[n] <- x1[n]; \n",
    "  for (n in 1:N2) \n",
    "    x[N1 + n] <- x2[n];\n",
    "  for (i in 1:N) \n",
    "    mu[i] <- 0;\n",
    "  for (i in 1:N)\n",
    "    for (j in 1:N) {\n",
    "      Sigma[i, j] <- exp(-pow(x[i] - x[j],2)) + if_else(i==j, 0.1, 0.0);\n",
    "    }\n",
    "  L <- cholesky_decompose(Sigma);\n",
    "}\n",
    "    \n",
    "parameters {\n",
    "  vector[N2] y2;\n",
    "}\n",
    "\n",
    "model {\n",
    "  vector[N] y;\n",
    "  for (n in 1:N1) y[n] <- y1[n];\n",
    "  for (n in 1:N2) y[N1 + n] <- y2[n];\n",
    "  y ~ multi_normal_cholesky(mu,L);  \n",
    "}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Compiled Stan Model\n",
    "sm_p_Cholesky_speedup = StanModel(model_code=GP_test_predict_model_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generate some simple fake noisy data (from DFM Goerge tutorial).\n",
    "N1 = 10\n",
    "N2 = 500\n",
    "x1 = N * np.sort(np.random.rand(N))\n",
    "yerr = 0.2 * np.ones_like(x)\n",
    "y1 = np.sin(x) + yerr * np.random.randn(len(x))\n",
    "x2 = np.linspace(0, 10, 500)\n",
    "\n",
    "#data_p = {'N':N, 'N1':N1, 'N2':N2, 'x1':x, 'x2':t, 'y1':y}\n",
    "data_p = {'N1':N1, 'N2':N2, 'x1':x1, 'x2':x2, 'y1':y1}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# syntax for initialization dictionary:\n",
    "#init = [{'lnf0':0.66,'alpha':-1.82,'beta':-0.65}]\n",
    "\n",
    "fit_p = sm_p.sampling(data=data_p, iter=10, chains=5, n_jobs=-1)\n",
    "\n",
    "# Return a dictionary of arrays of posterior samples\n",
    "la_p = fit_p.extract(permuted=True)  \n",
    "\n",
    "y2 = la_p['y2']\n",
    "\n",
    "a = fit_p.extract(permuted=False)\n",
    "\n",
    "print(fit_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
